{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CIPEC import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da128e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Qibo 0.2.14|INFO|2025-02-21 09:51:55]: Using numpy backend on /CPU:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qibo import quantum_info as qi\n",
    "from qibo import Circuit, gates, set_backend\n",
    "from qibo.backends import NumpyBackend\n",
    "from qibo.noise import NoiseModel, DepolarizingError\n",
    "from qibo.quantum_info.metrics import diamond_norm\n",
    "\n",
    "import cvxpy as cp\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import os.path\n",
    "import csv\n",
    "\n",
    "set_backend(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "671a324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(B):\n",
    "    \n",
    "    \"\"\" naive Gram matrix \"\"\"\n",
    "    \n",
    "    d = len(B)\n",
    "    G = 1.j*np.zeros([d,d])\n",
    "    for ii in range(d):\n",
    "        for jj in range(ii+1,d):\n",
    "            G[ii,jj] = np.trace(B[ii].conj().T@B[jj])\n",
    "    G = (G+G.conj().T)\n",
    "    for ii in range(d):\n",
    "        G[ii,ii] = np.trace(B[ii].conj().T@B[ii])\n",
    "    return G\n",
    "\n",
    "def update_gram_matrix(oldG, B_prev, new_channel):\n",
    "    \n",
    "    \"\"\" more efficient Gram matrix that only adds a new row/column to an old one \"\"\"\n",
    "    \n",
    "    d = len(oldG)\n",
    "    G = np.zeros((d+1,d+1), dtype='complex_')\n",
    "    G[:-1,:-1] = oldG\n",
    "    for ii in range(d):\n",
    "        G[ii,-1] = np.trace(B_prev[ii].conj().T@new_channel, dtype='complex_')\n",
    "        G[-1,ii] = G[ii,-1].conj()\n",
    "    G[-1,-1] = np.trace(new_channel.conj().T@new_channel, dtype='complex_')\n",
    "    return G\n",
    "\n",
    "def clifford_T_channels(n_qubits, include_T=True):\n",
    "\n",
    "    \"\"\" returns dict of unitary channels in Choi representation \"\"\"\n",
    "\n",
    "    # 1q gates\n",
    "    I = np.eye(2)\n",
    "    H = (1.0/np.sqrt(2.0))*np.array(np.array([[1.,  1.],[1., -1.]]))\n",
    "    S = np.array(np.array([[1., 0.],[0., 1.j]]))\n",
    "    T = np.array(np.array([[1., 0.],[0., np.exp(1j*np.pi/4.)]]))\n",
    "\n",
    "    # 2q gates\n",
    "    II = np.eye(2**2)\n",
    "    HI = np.kron(H,I)\n",
    "    IH = np.kron(I,H)\n",
    "    SI = np.kron(S,I)\n",
    "    IS = np.kron(I,S)\n",
    "    TI = np.kron(T,I)\n",
    "    IT = np.kron(I,T)\n",
    "    HS = np.kron(H,S)\n",
    "    SH = np.kron(S,H)\n",
    "    HT = np.kron(H,T)\n",
    "    TH = np.kron(T,H)\n",
    "    TS = np.kron(T,S)\n",
    "    ST = np.kron(S,T)\n",
    "    CX = np.array([[1., 0., 0., 0.],[0., 1., 0., 0.],[0., 0., 0., 1.],[0., 0., 1., 0.]])\n",
    "    XC = np.array([[1., 0., 0., 0.],[0., 0., 0., 1.],[0., 0., 1., 0.],[0., 1., 0., 0.]])\n",
    "\n",
    "    # corresponding channels in Choi rep.\n",
    "    if n_qubits == 1:\n",
    "        unitary_gates = {\"H\": H, \"S\": S}\n",
    "        if include_T:\n",
    "            unitary_gates[\"T\"] = T\n",
    "\n",
    "    if n_qubits == 2:\n",
    "        unitary_gates = {\"HI\": HI, \"IH\": IH, \"SI\": SI, \"IS\": IS, \"HS\": HS, \"SH\": SH, \"CX\": CX, \"XC\": XC}\n",
    "        if include_T:\n",
    "            unitary_gates[\"TI\"] = TI\n",
    "            unitary_gates[\"IT\"] = IT\n",
    "            unitary_gates[\"HT\"] = HT\n",
    "            unitary_gates[\"TH\"] = TH\n",
    "            unitary_gates[\"ST\"] = ST\n",
    "            unitary_gates[\"TS\"] = TS\n",
    "#         unitary_gates = {\"HI\": HI, \"IH\": IH, \"SI\": SI, \"IS\": IS, \"TI\": TI, \"IT\": IT,\"HS\": HS,\n",
    "#                          \"HT\": HT, \"SH\": SH, \"ST\": ST, \"TS\": TS, \"TH\": TH, \"CX\": CX, \"XC\": XC}\n",
    "\n",
    "    unitary_channels = {k:qi.to_choi(v) for k,v in unitary_gates.items()}\n",
    "\n",
    "    return unitary_channels\n",
    "\n",
    "def state_prep_channels(n_qubits):\n",
    "\n",
    "    \"\"\" returns dict of |+>, |+y> and |0> state prep channels in Choi representation \"\"\"\n",
    "\n",
    "    I = np.eye(2)\n",
    "    II = np.eye(2**2)\n",
    "\n",
    "\n",
    "    # 1q state projectors\n",
    "    projector_0x = 0.5*np.array([[1., 1.],[1., 1.]]) # projector on the |+> state\n",
    "    projector_0y = 0.5*np.array([[1., 1.j],[-1.j, 1.]]) # projector on the |+y> state\n",
    "    projector_0z = np.array([[1., 0.],[0., 0.]]) # projector on the |0> state\n",
    "\n",
    "    # 2q state projectors\n",
    "    projector_0xI = np.kron(projector_0x,I)\n",
    "    projector_0yI = np.kron(projector_0y,I)\n",
    "    projector_0zI = np.kron(projector_0z,I)\n",
    "    Iprojector_0x = np.kron(I,projector_0x)\n",
    "    Iprojector_0y = np.kron(I,projector_0y)\n",
    "    Iprojector_0z = np.kron(I,projector_0z)\n",
    "    projector_0x0x = np.kron(projector_0x,projector_0x)\n",
    "    projector_0x0y = np.kron(projector_0x,projector_0y)\n",
    "    projector_0x0z = np.kron(projector_0x,projector_0z)\n",
    "    projector_0y0x = np.kron(projector_0y,projector_0x)\n",
    "    projector_0y0y = np.kron(projector_0y,projector_0y)\n",
    "    projector_0y0z = np.kron(projector_0y,projector_0z)\n",
    "    projector_0z0x = np.kron(projector_0z,projector_0x)\n",
    "    projector_0z0y = np.kron(projector_0z,projector_0y)\n",
    "    projector_0z0z = np.kron(projector_0z,projector_0z)\n",
    "\n",
    "    # corresponding channels in Choi rep.\n",
    "    if n_qubits == 1:\n",
    "        channels = {\"Px\": np.kron(projector_0x, I), \"Py\": np.kron(projector_0y, I), \"Pz\": np.kron(projector_0z, I)}\n",
    "\n",
    "    if n_qubits == 2:\n",
    "        channels = {\"PxI\": np.kron(projector_0xI, II), \"PyI\": np.kron(projector_0yI, II), \"PzI\": np.kron(projector_0zI, II),\n",
    "                    \"IPx\": np.kron(Iprojector_0x, II), \"IPy\": np.kron(Iprojector_0y, II), \"IPz\": np.kron(Iprojector_0z, II),\n",
    "                    \"PxPx\": np.kron(projector_0x0x, II), \"PxPy\": np.kron(projector_0x0y, II), \"PxPz\": np.kron(projector_0x0z, II),\n",
    "                    \"PyPx\": np.kron(projector_0y0x, II), \"PyPy\": np.kron(projector_0y0y, II), \"PyPz\": np.kron(projector_0y0z, II),\n",
    "                    \"PzPx\": np.kron(projector_0z0x, II), \"PzPy\": np.kron(projector_0z0y, II), \"PzPz\": np.kron(projector_0z0z, II)}\n",
    "\n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bd866740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(data,filename):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(data)\n",
    "        \n",
    "\n",
    "def noiseless_basis(nqubits, include_T=True):\n",
    "    \n",
    "    \"\"\" builds a minimal basis by selecting LI sequences of unitary channels, then adding state prep channels \"\"\"\n",
    "\n",
    "    # filename to export (in case of first run) or import (if already ran before)\n",
    "    if include_T:\n",
    "        filename = str(nqubits)+'qbasis_cliffplusT_noiseless.csv' \n",
    "    else:\n",
    "        filename = str(nqubits)+'qbasis_cliff_noiseless.csv'         \n",
    "\n",
    "    # first check if it has already been computed\n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename, newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            composite_keys = [tuple(k) for k in list(reader)]\n",
    "\n",
    "        unitary_channels = clifford_T_channels(nqubits,include_T)\n",
    "        nonunitary_channels = state_prep_channels(nqubits)\n",
    "        unitary_channels.update(nonunitary_channels) # merge the two dicts\n",
    "        B = {}\n",
    "        for k in composite_keys:\n",
    "            new_channel = qi.choi_to_liouville(unitary_channels[k[0]])\n",
    "            if len(k) > 1:\n",
    "                for i in range(1,len(k)):\n",
    "                    new_channel = qi.choi_to_liouville(unitary_channels[k[i]])@new_channel\n",
    "            new_channel = qi.liouville_to_choi(new_channel)\n",
    "            B[k] = new_channel\n",
    "        print('Loaded pre-computed basis')\n",
    "\n",
    "    # if not then let's compute\n",
    "    else:\n",
    "        unitary_channels = clifford_T_channels(nqubits,include_T)\n",
    "        nonunitary_channels = state_prep_channels(nqubits)\n",
    "\n",
    "        CPTP_dim = 2**(4*nqubits) - 2**(2*nqubits) + 1\n",
    "        print(f'dim(CPTP)={CPTP_dim}\\n')\n",
    "\n",
    "        # start composing only unitary channels\n",
    "        keys = list(unitary_channels.keys())\n",
    "        composite_keys = []\n",
    "        B = {}\n",
    "        rank = 0\n",
    "\n",
    "        # words of length 1\n",
    "        for k in list(itertools.product(keys)):\n",
    "            composite_keys.append(tuple([k[0]]))\n",
    "        # words of length 2\n",
    "        for k in list(itertools.product(keys,keys)):\n",
    "            composite_keys.append((k[0],k[1]))\n",
    "        # words of length 3\n",
    "        for k in list(itertools.product(keys,keys,keys)):\n",
    "            composite_keys.append((k[0],k[1],k[2]))\n",
    "        # words of length 4\n",
    "        for k in list(itertools.product(keys,keys,keys,keys)):\n",
    "            composite_keys.append((k[0],k[1],k[2],k[3]))\n",
    "\n",
    "        print(f\"Starting sequences of unitaries. There are {len(composite_keys)} candidate words up to L=4 to try.\")\n",
    "\n",
    "        composite_keys = tqdm(composite_keys)\n",
    "        G = np.empty([0,0], dtype='complex_')\n",
    "        for k in composite_keys:\n",
    "            new_channel = qi.choi_to_liouville(unitary_channels[k[0]])\n",
    "            if len(k) > 1:\n",
    "                for i in range(1,len(k)):\n",
    "                    new_channel = qi.choi_to_liouville(unitary_channels[k[i]])@new_channel\n",
    "            new_channel = qi.liouville_to_choi(new_channel)\n",
    "            GU = update_gram_matrix(G, list(B.values()), new_channel)\n",
    "            if np.linalg.matrix_rank(GU) > rank:\n",
    "                rank += 1\n",
    "                B[k] = new_channel\n",
    "                G = GU\n",
    "                if rank == CPTP_dim-len(nonunitary_channels):\n",
    "                    print(\"Success!\")\n",
    "                    break\n",
    "            else:\n",
    "                pass\n",
    "            composite_keys.set_description(f'Current rank(G) = {rank}')\n",
    "\n",
    "        print(f\"Achieved rank(G)={rank}\\n\")\n",
    "\n",
    "        # now add state prep channels\n",
    "        keys = [tuple([k]) for k in list(nonunitary_channels.keys())]\n",
    "        print(f\"Adding now state prep channels\")\n",
    "        keys = tqdm(keys)\n",
    "\n",
    "        for k in keys:\n",
    "            new_channel = nonunitary_channels[k[0]]\n",
    "            GU = update_gram_matrix(G, list(B.values()), new_channel)\n",
    "            if np.linalg.matrix_rank(GU) > rank:\n",
    "                rank += 1\n",
    "                B[k] = new_channel\n",
    "                G = GU\n",
    "                if rank == CPTP_dim:\n",
    "                    write(list(B.keys()), filename)\n",
    "                    print(f'Success!\\nAchieved rank(G)={rank}. Results were written at file \"{filename}\"')\n",
    "                    break\n",
    "            else:\n",
    "                pass\n",
    "        keys.set_description(f'Current rank(G) = {rank}')\n",
    "\n",
    "        if rank < CPTP_dim:\n",
    "          print(f\"Unable to span the entire space of CPTPs\")\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df9ce1c",
   "metadata": {},
   "source": [
    "# 1) Noiseless basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1d3d9e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim(CPTP)=13\n",
      "\n",
      "Starting sequences of unitaries. There are 120 candidate words up to L=4 to try.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5a5c83328e43eba1e895c19a0f8bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Achieved rank(G)=10\n",
      "\n",
      "Adding now state prep channels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420c9c7b30434deb8bd939389ea45751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Achieved rank(G)=13. Results were written at file \"1qbasis_cliffplusT_noiseless.csv\"\n",
      "\n",
      "The following 13 channels form a basis of 1q CPTP maps:\n",
      "[('H',), ('S',), ('T',), ('H', 'H'), ('H', 'S'), ('H', 'T'), ('S', 'H'), ('T', 'H'), ('H', 'S', 'H'), ('S', 'H', 'T'), ('Px',), ('Py',), ('Pz',)]\n"
     ]
    }
   ],
   "source": [
    "# 1-qubit CPTP maps (including T)\n",
    "B = noiseless_basis(1,include_T=True)\n",
    "\n",
    "print(f\"\\nThe following {len(B)} channels form a basis of 1q CPTP maps:\\n{list(B.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1bb685e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim(CPTP)=13\n",
      "\n",
      "Starting sequences of unitaries. There are 30 candidate words up to L=4 to try.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3d1fa0700a454493c007be78195944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Achieved rank(G)=10\n",
      "\n",
      "Adding now state prep channels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615a04d87a474fde8eac905b8770ae0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Achieved rank(G)=13. Results were written at file \"1qbasis_cliff_noiseless.csv\"\n",
      "\n",
      "The following 13 channels form a basis of 1q CPTP maps:\n",
      "[('H',), ('S',), ('H', 'H'), ('H', 'S'), ('S', 'H'), ('S', 'S'), ('H', 'S', 'H'), ('H', 'S', 'S'), ('S', 'H', 'S'), ('S', 'H', 'S', 'S'), ('Px',), ('Py',), ('Pz',)]\n"
     ]
    }
   ],
   "source": [
    "# 1-qubit CPTP maps (excluding T)\n",
    "B = noiseless_basis(1,include_T=False)\n",
    "\n",
    "print(f\"\\nThe following {len(B)} channels form a basis of 1q CPTP maps:\\n{list(B.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2dedff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim(CPTP)=241\n",
      "\n",
      "Starting sequences of unitaries. There are 41370 candidate words up to L=4 to try.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916e0744646f4df9a2585bd91329bc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Achieved rank(G)=226\n",
      "\n",
      "Adding now state prep channels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742a2d9651664a9bbeecc7f4fa3c3c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Achieved rank(G)=241. Results were written at file \"2qbasis_cliffplusT_noiseless.csv\"\n",
      "\n",
      "The following 241 channels form a basis of 2q CPTP maps:\n",
      "[('HI',), ('IH',), ('SI',), ('IS',), ('HS',), ('SH',), ('CX',), ('XC',), ('TI',), ('IT',), ('HT',), ('TH',), ('ST',), ('TS',), ('HI', 'HI'), ('HI', 'IH'), ('HI', 'SI'), ('HI', 'SH'), ('HI', 'CX'), ('HI', 'XC'), ('HI', 'TI'), ('HI', 'TH'), ('HI', 'ST'), ('HI', 'TS'), ('IH', 'IS'), ('IH', 'HS'), ('IH', 'CX'), ('IH', 'XC'), ('IH', 'IT'), ('IH', 'HT'), ('IH', 'ST'), ('IH', 'TS'), ('SI', 'HI'), ('SI', 'IS'), ('SI', 'HS'), ('SI', 'CX'), ('SI', 'XC'), ('SI', 'HT'), ('SI', 'ST'), ('IS', 'IH'), ('IS', 'SH'), ('IS', 'CX'), ('IS', 'XC'), ('IS', 'TH'), ('HS', 'IH'), ('HS', 'SI'), ('HS', 'SH'), ('HS', 'CX'), ('HS', 'XC'), ('HS', 'TH'), ('HS', 'TS'), ('SH', 'HI'), ('SH', 'IS'), ('SH', 'HS'), ('SH', 'CX'), ('SH', 'XC'), ('SH', 'HT'), ('SH', 'ST'), ('CX', 'HI'), ('CX', 'IH'), ('CX', 'IS'), ('CX', 'HS'), ('CX', 'SH'), ('CX', 'XC'), ('CX', 'TI'), ('CX', 'IT'), ('CX', 'HT'), ('CX', 'TH'), ('CX', 'ST'), ('CX', 'TS'), ('XC', 'HI'), ('XC', 'IH'), ('XC', 'SI'), ('XC', 'HS'), ('XC', 'SH'), ('XC', 'CX'), ('XC', 'TI'), ('XC', 'IT'), ('XC', 'HT'), ('XC', 'TH'), ('XC', 'ST'), ('XC', 'TS'), ('TI', 'HI'), ('TI', 'HS'), ('TI', 'XC'), ('TI', 'HT'), ('IT', 'IH'), ('IT', 'SH'), ('IT', 'CX'), ('IT', 'TH'), ('HT', 'IH'), ('HT', 'SH'), ('HT', 'CX'), ('HT', 'XC'), ('HT', 'TH'), ('TH', 'HI'), ('TH', 'HS'), ('TH', 'CX'), ('TH', 'XC'), ('TH', 'HT'), ('ST', 'CX'), ('ST', 'XC'), ('HI', 'IH', 'CX'), ('HI', 'IH', 'XC'), ('HI', 'IH', 'ST'), ('HI', 'IH', 'TS'), ('HI', 'SI', 'HI'), ('HI', 'SI', 'HS'), ('HI', 'SI', 'CX'), ('HI', 'SI', 'XC'), ('HI', 'SI', 'HT'), ('HI', 'SH', 'HI'), ('HI', 'SH', 'IS'), ('HI', 'SH', 'HS'), ('HI', 'SH', 'CX'), ('HI', 'SH', 'XC'), ('HI', 'SH', 'HT'), ('HI', 'SH', 'ST'), ('HI', 'CX', 'HI'), ('HI', 'CX', 'IH'), ('HI', 'CX', 'IS'), ('HI', 'CX', 'HS'), ('HI', 'CX', 'SH'), ('HI', 'CX', 'XC'), ('HI', 'CX', 'TI'), ('HI', 'CX', 'IT'), ('HI', 'CX', 'HT'), ('HI', 'CX', 'TH'), ('HI', 'CX', 'ST'), ('HI', 'CX', 'TS'), ('HI', 'XC', 'IH'), ('HI', 'XC', 'SI'), ('HI', 'XC', 'SH'), ('HI', 'XC', 'CX'), ('HI', 'XC', 'TH'), ('HI', 'XC', 'ST'), ('HI', 'ST', 'CX'), ('IH', 'IS', 'IH'), ('IH', 'IS', 'SH'), ('IH', 'IS', 'CX'), ('IH', 'IS', 'XC'), ('IH', 'IS', 'TH'), ('IH', 'HS', 'IH'), ('IH', 'HS', 'SH'), ('IH', 'HS', 'CX'), ('IH', 'HS', 'XC'), ('IH', 'HS', 'TH'), ('IH', 'CX', 'IS'), ('IH', 'CX', 'HS'), ('IH', 'CX', 'XC'), ('IH', 'CX', 'IT'), ('IH', 'CX', 'HT'), ('IH', 'CX', 'ST'), ('IH', 'XC', 'SI'), ('IH', 'XC', 'SH'), ('IH', 'XC', 'CX'), ('IH', 'XC', 'TI'), ('IH', 'XC', 'IT'), ('IH', 'XC', 'TH'), ('IH', 'XC', 'ST'), ('IH', 'XC', 'TS'), ('IH', 'ST', 'XC'), ('SI', 'HI', 'CX'), ('SI', 'HI', 'XC'), ('SI', 'HI', 'TI'), ('SI', 'HI', 'TH'), ('SI', 'HS', 'IH'), ('SI', 'HS', 'SH'), ('SI', 'HS', 'CX'), ('SI', 'HS', 'TH'), ('SI', 'CX', 'HI'), ('SI', 'CX', 'HS'), ('SI', 'CX', 'XC'), ('SI', 'CX', 'HT'), ('SI', 'XC', 'IH'), ('SI', 'XC', 'SH'), ('SI', 'XC', 'CX'), ('SI', 'XC', 'TH'), ('SI', 'HT', 'IH'), ('SI', 'HT', 'CX'), ('IS', 'IH', 'CX'), ('IS', 'IH', 'XC'), ('IS', 'IH', 'IT'), ('IS', 'IH', 'HT'), ('IS', 'SH', 'HS'), ('IS', 'SH', 'XC'), ('IS', 'SH', 'HT'), ('IS', 'CX', 'HI'), ('IS', 'CX', 'HS'), ('IS', 'CX', 'XC'), ('IS', 'CX', 'HT'), ('IS', 'XC', 'IH'), ('IS', 'XC', 'SH'), ('IS', 'XC', 'CX'), ('IS', 'XC', 'TH'), ('IS', 'TH', 'HI'), ('IS', 'TH', 'XC'), ('HS', 'IH', 'CX'), ('HS', 'IH', 'XC'), ('HS', 'IH', 'ST'), ('HS', 'SI', 'CX'), ('HS', 'SH', 'XC'), ('HS', 'SH', 'HT'), ('HS', 'CX', 'XC'), ('HS', 'XC', 'CX'), ('SH', 'HI', 'XC'), ('SH', 'HI', 'TS'), ('SH', 'IS', 'XC'), ('SH', 'HS', 'CX'), ('SH', 'HS', 'TH'), ('CX', 'HI', 'CX'), ('CX', 'HI', 'XC'), ('CX', 'HI', 'ST'), ('CX', 'HI', 'TS'), ('CX', 'IS', 'XC'), ('CX', 'HS', 'SH'), ('CX', 'HS', 'CX'), ('CX', 'XC', 'CX'), ('CX', 'XC', 'IT'), ('CX', 'TI', 'HI'), ('CX', 'ST', 'XC'), ('XC', 'SI', 'CX'), ('HI', 'CX', 'IS', 'XC'), ('IH', 'XC', 'SI', 'CX'), ('SI', 'HI', 'XC', 'CX'), ('IS', 'IH', 'CX', 'XC'), ('PxI',), ('PyI',), ('PzI',), ('IPx',), ('IPy',), ('IPz',), ('PxPx',), ('PxPy',), ('PxPz',), ('PyPx',), ('PyPy',), ('PyPz',), ('PzPx',), ('PzPy',), ('PzPz',)]\n"
     ]
    }
   ],
   "source": [
    "# 2-qubit CPTP maps (including T)\n",
    "B = noiseless_basis(2, include_T=True)\n",
    "\n",
    "print(f\"\\nThe following {len(B)} channels form a basis of 2q CPTP maps:\\n{list(B.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0d0c3298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim(CPTP)=241\n",
      "\n",
      "Starting sequences of unitaries. There are 4680 candidate words up to L=4 to try.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437c66f45a444b129b8a239a8010e5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Achieved rank(G)=226\n",
      "\n",
      "Adding now state prep channels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13271d8cae840db91efd439bc22cc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Achieved rank(G)=241. Results were written at file \"2qbasis_cliff_noiseless.csv\"\n",
      "\n",
      "The following 241 channels form a basis of 2q CPTP maps:\n",
      "[('HI',), ('IH',), ('SI',), ('IS',), ('HS',), ('SH',), ('CX',), ('XC',), ('HI', 'HI'), ('HI', 'IH'), ('HI', 'SI'), ('HI', 'SH'), ('HI', 'CX'), ('HI', 'XC'), ('IH', 'IS'), ('IH', 'HS'), ('IH', 'CX'), ('IH', 'XC'), ('SI', 'HI'), ('SI', 'SI'), ('SI', 'IS'), ('SI', 'HS'), ('SI', 'SH'), ('SI', 'CX'), ('SI', 'XC'), ('IS', 'IH'), ('IS', 'IS'), ('IS', 'HS'), ('IS', 'SH'), ('IS', 'CX'), ('IS', 'XC'), ('HS', 'IH'), ('HS', 'SI'), ('HS', 'SH'), ('HS', 'CX'), ('HS', 'XC'), ('SH', 'HI'), ('SH', 'IS'), ('SH', 'HS'), ('SH', 'CX'), ('SH', 'XC'), ('CX', 'HI'), ('CX', 'IH'), ('CX', 'IS'), ('CX', 'HS'), ('CX', 'SH'), ('CX', 'XC'), ('XC', 'HI'), ('XC', 'IH'), ('XC', 'SI'), ('XC', 'HS'), ('XC', 'SH'), ('XC', 'CX'), ('HI', 'IH', 'CX'), ('HI', 'IH', 'XC'), ('HI', 'SI', 'HI'), ('HI', 'SI', 'SI'), ('HI', 'SI', 'HS'), ('HI', 'SI', 'SH'), ('HI', 'SI', 'CX'), ('HI', 'SI', 'XC'), ('HI', 'SH', 'HI'), ('HI', 'SH', 'IS'), ('HI', 'SH', 'HS'), ('HI', 'SH', 'CX'), ('HI', 'SH', 'XC'), ('HI', 'CX', 'HI'), ('HI', 'CX', 'IH'), ('HI', 'CX', 'IS'), ('HI', 'CX', 'HS'), ('HI', 'CX', 'SH'), ('HI', 'CX', 'XC'), ('HI', 'XC', 'HI'), ('HI', 'XC', 'IH'), ('HI', 'XC', 'SI'), ('HI', 'XC', 'HS'), ('HI', 'XC', 'SH'), ('HI', 'XC', 'CX'), ('IH', 'IS', 'IH'), ('IH', 'IS', 'IS'), ('IH', 'IS', 'HS'), ('IH', 'IS', 'SH'), ('IH', 'IS', 'CX'), ('IH', 'IS', 'XC'), ('IH', 'HS', 'IH'), ('IH', 'HS', 'SH'), ('IH', 'HS', 'CX'), ('IH', 'HS', 'XC'), ('IH', 'CX', 'IS'), ('IH', 'CX', 'HS'), ('IH', 'CX', 'SH'), ('IH', 'CX', 'XC'), ('IH', 'XC', 'SI'), ('IH', 'XC', 'HS'), ('IH', 'XC', 'SH'), ('IH', 'XC', 'CX'), ('SI', 'HI', 'SI'), ('SI', 'HI', 'SH'), ('SI', 'HI', 'CX'), ('SI', 'HI', 'XC'), ('SI', 'SI', 'IS'), ('SI', 'SI', 'HS'), ('SI', 'SI', 'CX'), ('SI', 'SI', 'XC'), ('SI', 'IS', 'IS'), ('SI', 'IS', 'HS'), ('SI', 'IS', 'SH'), ('SI', 'IS', 'CX'), ('SI', 'IS', 'XC'), ('SI', 'HS', 'IH'), ('SI', 'HS', 'SI'), ('SI', 'HS', 'SH'), ('SI', 'HS', 'CX'), ('SI', 'HS', 'XC'), ('SI', 'SH', 'IS'), ('SI', 'SH', 'HS'), ('SI', 'SH', 'CX'), ('SI', 'SH', 'XC'), ('SI', 'CX', 'HI'), ('SI', 'CX', 'IS'), ('SI', 'CX', 'HS'), ('SI', 'CX', 'SH'), ('SI', 'CX', 'XC'), ('SI', 'XC', 'HI'), ('SI', 'XC', 'IH'), ('SI', 'XC', 'SI'), ('SI', 'XC', 'HS'), ('SI', 'XC', 'SH'), ('SI', 'XC', 'CX'), ('IS', 'IH', 'IS'), ('IS', 'IH', 'HS'), ('IS', 'IH', 'CX'), ('IS', 'IH', 'XC'), ('IS', 'IS', 'SH'), ('IS', 'IS', 'CX'), ('IS', 'IS', 'XC'), ('IS', 'HS', 'SI'), ('IS', 'HS', 'SH'), ('IS', 'HS', 'CX'), ('IS', 'HS', 'XC'), ('IS', 'SH', 'IS'), ('IS', 'SH', 'HS'), ('IS', 'SH', 'CX'), ('IS', 'SH', 'XC'), ('IS', 'CX', 'HI'), ('IS', 'CX', 'IH'), ('IS', 'CX', 'IS'), ('IS', 'CX', 'HS'), ('IS', 'CX', 'SH'), ('IS', 'CX', 'XC'), ('IS', 'XC', 'IH'), ('IS', 'XC', 'SI'), ('IS', 'XC', 'SH'), ('IS', 'XC', 'CX'), ('HS', 'IH', 'CX'), ('HS', 'IH', 'XC'), ('HS', 'SI', 'HS'), ('HS', 'SI', 'SH'), ('HS', 'SI', 'CX'), ('HS', 'SI', 'XC'), ('HS', 'SH', 'HI'), ('HS', 'SH', 'IS'), ('HS', 'SH', 'HS'), ('HS', 'SH', 'CX'), ('HS', 'SH', 'XC'), ('HS', 'CX', 'HI'), ('HS', 'CX', 'IH'), ('HS', 'CX', 'IS'), ('HS', 'CX', 'HS'), ('HS', 'CX', 'SH'), ('HS', 'CX', 'XC'), ('HS', 'XC', 'IH'), ('HS', 'XC', 'SH'), ('HS', 'XC', 'CX'), ('SH', 'HI', 'CX'), ('SH', 'HI', 'XC'), ('SH', 'IS', 'HS'), ('SH', 'IS', 'CX'), ('SH', 'IS', 'XC'), ('SH', 'HS', 'IH'), ('SH', 'HS', 'SI'), ('SH', 'HS', 'SH'), ('SH', 'HS', 'CX'), ('SH', 'HS', 'XC'), ('SH', 'CX', 'HS'), ('SH', 'CX', 'XC'), ('SH', 'XC', 'HI'), ('SH', 'XC', 'IH'), ('SH', 'XC', 'SI'), ('SH', 'XC', 'HS'), ('SH', 'XC', 'CX'), ('CX', 'HI', 'CX'), ('CX', 'HI', 'XC'), ('CX', 'IH', 'XC'), ('CX', 'IS', 'HS'), ('CX', 'IS', 'XC'), ('CX', 'HS', 'IH'), ('CX', 'HS', 'SI'), ('CX', 'HS', 'SH'), ('CX', 'HS', 'CX'), ('CX', 'HS', 'XC'), ('CX', 'SH', 'XC'), ('CX', 'XC', 'HI'), ('CX', 'XC', 'IH'), ('CX', 'XC', 'HS'), ('CX', 'XC', 'SH'), ('CX', 'XC', 'CX'), ('XC', 'HI', 'CX'), ('XC', 'IH', 'CX'), ('XC', 'IH', 'XC'), ('XC', 'SI', 'SH'), ('XC', 'SI', 'CX'), ('HI', 'SI', 'HI', 'CX'), ('HI', 'SI', 'SI', 'CX'), ('HI', 'SI', 'SH', 'CX'), ('HI', 'SI', 'CX', 'HI'), ('HI', 'SI', 'CX', 'HS'), ('HI', 'SI', 'CX', 'XC'), ('HI', 'SI', 'XC', 'IH'), ('HI', 'SI', 'XC', 'CX'), ('HI', 'CX', 'IS', 'HS'), ('HI', 'CX', 'IS', 'XC'), ('HI', 'CX', 'XC', 'CX'), ('IH', 'XC', 'SI', 'CX'), ('SI', 'HI', 'XC', 'CX'), ('IS', 'IH', 'CX', 'XC'), ('PxI',), ('PyI',), ('PzI',), ('IPx',), ('IPy',), ('IPz',), ('PxPx',), ('PxPy',), ('PxPz',), ('PyPx',), ('PyPy',), ('PyPz',), ('PzPx',), ('PzPy',), ('PzPz',)]\n"
     ]
    }
   ],
   "source": [
    "# 2-qubit CPTP maps (excluding T)\n",
    "B = noiseless_basis(2, include_T=False)\n",
    "\n",
    "print(f\"\\nThe following {len(B)} channels form a basis of 2q CPTP maps:\\n{list(B.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c1f761",
   "metadata": {},
   "source": [
    "# 2) Noisy basis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "99141e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise(B, noise):    \n",
    "    return {k:qi.liouville_to_choi(noise.to_liouville()@qi.choi_to_liouville(v)) for k,v in B.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9f015f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed basis\n",
      "Done!\n",
      "rank(G)=241\n"
     ]
    }
   ],
   "source": [
    "# Noise Model\n",
    "lam = .2\n",
    "noise = gates.DepolarizingChannel([0,1],lam)\n",
    "\n",
    "# Noisy basis\n",
    "B = noiseless_basis(2)\n",
    "B_noisy = apply_noise(B,noise)\n",
    "\n",
    "# Gram matrix and LI check\n",
    "G = gram_matrix(list(B_noisy.values()))\n",
    "print(f'rank(G)={np.linalg.matrix_rank(G)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_list = np.logspace(-3,0,50)[:-1]\n",
    "N_list = []\n",
    "B = noiseless_basis(2)\n",
    "\n",
    "for lam in lam_list:\n",
    "    \n",
    "    # Noise Model\n",
    "    noise = gates.DepolarizingChannel([0],lam)\n",
    "\n",
    "    # Noisy basis\n",
    "    B_noisy = apply_noise(B,noise)\n",
    "\n",
    "#     # Gram matrix and LI check\n",
    "#     G = gram(B_noisy)\n",
    "\n",
    "#     print(f\"rank(G) = {np.linalg.matrix_rank(G)}, dim(CPTP) = {2**4-2**2+1}\")\n",
    "\n",
    "    #solving the LP\n",
    "    prob, cj = solve_LP(U_rand_1q, B_noisy.values(), norm=\"l1\")\n",
    "    N_list.append(prob)\n",
    "    \n",
    "plt.figure(figsize=(8,5))    \n",
    "plt.plot(lam_list, N_list, '-o')\n",
    "plt.xlabel(r'Depolarizing strength $p$')\n",
    "plt.ylabel(r'$\\mathcal{N}$')\n",
    "plt.title(r'Negativity of a random U(2) in the noisy Takagi basis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773419b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
