{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7ca3028-719b-4a67-bd5b-d98313a4ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from more_itertools import run_length\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c39a63e-647b-4f75-8f60-45dd1e0c0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(letters, l):\n",
    "    aux = [letters]*l\n",
    "    return [''.join(k) for k in list(product(*aux))]\n",
    "    \n",
    "\n",
    "def simplification_rules(L):\n",
    "\n",
    "    rules = {}\n",
    "\n",
    "    if letters == ['H','T']:\n",
    "\n",
    "        # H rules\n",
    "        for n in range(1,L+1):\n",
    "            rules[f'H{n}'] = ('' if n%2==0 else 'H')\n",
    "\n",
    "        # T rules\n",
    "        rules['T1'] = 'T'\n",
    "        rules['T2'] = 'S'\n",
    "        rules['T4'] = 'Z'\n",
    "        rules['T8'] = ''\n",
    "        rules['T3'] = 'ST'\n",
    "        rules['T5'] = 'ZT'\n",
    "        rules['T6'] = 'ZS'\n",
    "        rules['T7'] = 'ZST'\n",
    "        for n in range(9,Lmax+1):\n",
    "            rules[f'T{n}'] = rules[f'T{n-8}']\n",
    "\n",
    "        # S rules\n",
    "        rules['S1'] = 'S'\n",
    "        rules['S2'] = 'Z'\n",
    "        rules['S3'] = 'ZS'\n",
    "        rules['S4'] = ''\n",
    "        for n in range(5,Lmax+1):\n",
    "                    rules[f'S{n}'] = rules[f'S{n-4}']\n",
    "\n",
    "        # Z rules\n",
    "        rules['Z1'] = 'Z'\n",
    "        rules['Z2'] = ''\n",
    "        for n in range(3,Lmax+1):\n",
    "                    rules[f'Z{n}'] = rules[f'Z{n-2}']        \n",
    "\n",
    "        # conjugation rules\n",
    "        rules['HZH'] = 'X'\n",
    "        rules['HSH'] = 'Sd'\n",
    "        rules['HSdH'] = 'S'\n",
    "        rules['HTH'] = 'Td'\n",
    "        rules['HTdH'] = 'T'\n",
    "        \n",
    "        return rules\n",
    "\n",
    "    else:\n",
    "        print('Rules not implemented!')\n",
    "        \n",
    "        \n",
    "def reduced_vocabulary(letters, Lmax): \n",
    "    \n",
    "    maxnsimp = 100 \n",
    "    \n",
    "    vocab = set([])\n",
    "    simp = {}\n",
    "    totalsize = np.sum([len(letters)**l for l in range(1,Lmax+1)])\n",
    "\n",
    "    print(f'There are {totalsize} words in the vocabulary with length up to {Lmax}')\n",
    "\n",
    "    # build vocab with a first round of simplification\n",
    "    for l in range(1,Lmax+1):\n",
    "        for k,v in simplification_rules(l).items(): \n",
    "            simp[k] = v\n",
    "        vocab_l = vocabulary(letters, l)\n",
    "        for word in vocab_l:\n",
    "            word = list(run_length.encode(word))\n",
    "            word = ' '.join([k[0]+str(k[1]) for k in word])\n",
    "            # print(f'Vocabulary using run length encoding:\\n{vocab}\\n')\n",
    "            word = word.split(' ')\n",
    "            word = [(simp[syl] if syl != '' else '') for syl in word]\n",
    "            word = ''.join(word)\n",
    "            vocab.add(word)\n",
    "\n",
    "    size = len(vocab) # will be updated    \n",
    "    print(f'\\n---- simplification #{1}: reduced to {size} unique words')\n",
    "\n",
    "    # few more rounds of simplification\n",
    "    for i in range(2,maxnsimp):\n",
    "\n",
    "        vocab = [list(run_length.encode(word)) for word in vocab]\n",
    "        vocab = [' '.join([k[0]+str(k[1]) for k in word]) for word in vocab]\n",
    "        # print(f'Vocabulary using run length encoding:\\n{vocab}\\n')\n",
    "        vocab = [word.split(' ') for word in vocab]\n",
    "        vocab = [[(simp[syl] if syl != '' else '') for syl in word] for word in vocab]\n",
    "        vocab = list(set([''.join(word) for word in vocab]))\n",
    "        print(f'\\n---- simplification #{i}: reduced to {len(vocab)} unique words')\n",
    "        if len(vocab) < size:\n",
    "            size = len(vocab)\n",
    "        else:\n",
    "            print(f'\\nDONE!\\n\\nCompressed to {round(100*size/totalsize,2)}% of the original vocabulary\\n')\n",
    "            break\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7411b02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 65534 words in the vocabulary with length up to 15\n",
      "\n",
      "---- simplification #1: reduced to 12649 unique words\n",
      "\n",
      "---- simplification #2: reduced to 8098 unique words\n",
      "\n",
      "---- simplification #3: reduced to 7158 unique words\n",
      "\n",
      "---- simplification #4: reduced to 7092 unique words\n",
      "\n",
      "---- simplification #5: reduced to 7074 unique words\n",
      "\n",
      "---- simplification #6: reduced to 7071 unique words\n",
      "\n",
      "---- simplification #7: reduced to 7071 unique words\n",
      "\n",
      "DONE!\n",
      "\n",
      "Compressed to 10.79% of the original vocabulary\n",
      "\n",
      "Total time: 1.28s\n",
      "\n",
      "Here are a few of the 7071 unique words:\n",
      "\n",
      "['', 'ZSHSHSHT', 'SHTHTHZHST', 'SHZHSTS', 'HTHSHTSHS', 'STZHSTHT', 'HZSHS', 'STHZSHT', 'HSHTHTHTST', 'THSHTHZHST', 'HTHSTHTST', 'TSTSHZ', 'SHZTHS', 'THSTZH', 'HTHTSTHSH', 'ZHTHT', 'STHTHSTHSTH', 'HZSTHZH', 'HTZSHTHS', 'SHTHSTHTHZ']\n",
      "\n",
      "From these, 198 are Cliffords:\n",
      "\n",
      "['', 'HZSHS', 'ZSZH', 'SHSZS', 'HZHZH', 'ZSHZS', 'HSHSZHS', 'SHSHSZ', 'HSHSHZS', 'HZSHZS', 'SHZ', 'SZHZS', 'HSZSH', 'ZHSZH', 'HSHZSHS', 'ZSHSHSH', 'HSZHZ', 'SZSHZ', 'HSHSZH', 'HZHSHZH', 'HSHSZS', 'HSHZSHSH', 'SHZSZ', 'ZS', 'HSHS', 'SHSHSZH', 'SHZSHSH', 'SHSZSH', 'SZHSHS', 'ZHS', 'HSHSHSHS', 'HZSHZSH', 'ZSH', 'HZSHZH', 'HSHSHZSH', 'HZSHSHZ', 'SHZSH', 'ZSHSHZ', 'S', 'SZSHSH', 'ZSHS', 'ZSZSH', 'HZSZ', 'SHSZHSH', 'HSHSHSHSHS', 'SHZHSHS', 'SHSHSHSHS', 'HZHZSH', 'HSHZH', 'HZHSHSHSH', 'ZHSHZS', 'HZSZS', 'SHSHZH', 'HZHSHSHS', 'ZHSZS', 'ZHSZ', 'HSZSHSH', 'HSHZHZH', 'SHSHZ', 'ZHSHZ', 'HSHSHZHS', 'ZHSHSHS', 'HZHZS', 'HZHZ', 'HZHSHS', 'HZSHSHS', 'HSHZ', 'SHSHSH', 'SZS', 'SHZSHZ', 'SH', 'ZSHSZ', 'SHS', 'HSHSH', 'ZHZS', 'Z', 'SHSHZSH', 'SHSZHS', 'SHZHZ', 'ZSHSH', 'SZHZ', 'HZSH', 'SHSHSHS', 'HZSZH', 'HSHSHSH', 'ZHZHZ', 'SHZHZSH', 'ZHZSHSH', 'SHSHSHZH', 'HZSHZHS', 'ZHSHS', 'HZHSHSH', 'ZHZHS', 'H', 'HSHZS', 'ZSZ', 'SHSHZHS', 'HSHZHS', 'HSHSHSZ', 'HSHSHSHZ', 'HZSHZ', 'ZHSHZSH', 'HSZH', 'HZHZHZ', 'ZSZHS', 'ZHZH', 'SZHSHSH', 'ZHSHZH', 'HZSHSH', 'HZHSHZS', 'SHZHZS', 'SHZHSHZ', 'HSHSHSHZH', 'SHZHS', 'SHSHSHSH', 'HSHZHSHSH', 'HZHZSHS', 'ZHZHSHS', 'SHZHZH', 'SHSHZS', 'HSHZSH', 'SHZSHS', 'ZHSHSHZ', 'HZSHSHSH', 'SZ', 'HSZHSH', 'SHZHZHS', 'HZHSHZ', 'ZSHSHZH', 'HZHZHSH', 'ZHZHZH', 'HSHZHZ', 'SHZS', 'SHZH', 'HSZSHS', 'HZHZHS', 'HSHSZSH', 'HSZHZH', 'ZH', 'HSHSHZHSH', 'HSHSHZH', 'SZH', 'SHSZ', 'HZS', 'ZHSHSH', 'ZSHSHS', 'ZHZSHS', 'SHZSHSHS', 'HSHSHZ', 'HZHSZH', 'ZHSHZHS', 'HSZ', 'ZSHSHSHS', 'HSHSHS', 'ZSHZSH', 'SHSHS', 'SHSHZHSH', 'ZHZHSH', 'HSZS', 'HSZHS', 'HSHSHSHSH', 'SHZHSH', 'ZSZS', 'HS', 'SHSHSHSHSH', 'HZHS', 'SZHSH', 'SZSHS', 'HZHSZ', 'ZSHZHSH', 'ZSHZ', 'HSZHSHS', 'SHSHSHZ', 'HSH', 'ZHSHSHSH', 'SHZHSHSH', 'HZH', 'SHZSHZH', 'SZHS', 'SHSH', 'ZHZSH', 'HSHZHSHS', 'HSHZSHZ', 'HSHZHZS', 'SZHZH', 'SHSZH', 'SHSHZSHS', 'ZHZ', 'HSHZHSH', 'ZSHZHS', 'SHSHSHZS', 'SZSH', 'ZHSH', 'SHSHZHZ', 'HSHSZ', 'HZ', 'ZSHZH', 'HZHSH']\n"
     ]
    }
   ],
   "source": [
    "letters = ['H','T']\n",
    "Lmax = 15\n",
    "\n",
    "start = time.time()\n",
    "vocab = reduced_vocabulary(letters, Lmax)\n",
    "end = time.time()\n",
    "print(f'Total time: {round(end-start,2)}s\\n')\n",
    "\n",
    "print(f'Here are a few of the {len(vocab)} unique words:\\n\\n{vocab[:20]}')    \n",
    "\n",
    "vocab_cliff = [w for w in vocab if w.count('T')==0]\n",
    "print(f'\\nFrom these, {len(vocab_cliff)} are Cliffords:\\n')\n",
    "print(vocab_cliff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42533179-32ec-47a0-a719-c8c5c5eac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######## memory inneficient implementation (stores the entire vocab before simplifying)\n",
    "\n",
    "# letters = ['H','T']\n",
    "# L = 15\n",
    "# maxnsimp = 100\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# vocab = []\n",
    "# simp = {}\n",
    "# for l in range(1,L+1):\n",
    "#     vocab = vocab + vocabulary(letters, l)\n",
    "#     for k,v in simplification_rules(l).items():\n",
    "#         simp[k] = v\n",
    "# totalsize = len(vocab)\n",
    "# size = totalsize # will be updated\n",
    "\n",
    "# print(f'There are {size} words in the vocabulary with length up to {L}')\n",
    "\n",
    "# for i in range(1,maxnsimp):\n",
    "\n",
    "#     vocab = [list(run_length.encode(word)) for word in vocab]\n",
    "#     vocab = [' '.join([k[0]+str(k[1]) for k in word]) for word in vocab]\n",
    "#     # print(f'Vocabulary using run length encoding:\\n{vocab}\\n')\n",
    "#     vocab = [word.split(' ') for word in vocab]\n",
    "#     vocab = [[(simp[syl] if syl != '' else '') for syl in word] for word in vocab]\n",
    "#     vocab = list(set([''.join(word) for word in vocab]))\n",
    "#     print(f'\\n---- simplification #{i}: reduced to {len(vocab)} unique words')\n",
    "#     if len(vocab) < size:\n",
    "#         size = len(vocab)\n",
    "#     else:\n",
    "#         print(f'\\nDONE!\\n\\nCompressed to {round(100*size/totalsize,2)}% of the original vocabulary\\n')\n",
    "#         break\n",
    "\n",
    "# print(f'Here are some of the unique words:\\n\\n{vocab[:50]}')\n",
    "\n",
    "# end = time.time()\n",
    "# print(f'\\nTotal time: {round(end-start,2)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507f813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
